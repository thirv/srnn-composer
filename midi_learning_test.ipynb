{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from music21 import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing midi_s2/chpn_op23_format0.mid\n",
      "3116\n",
      "['C#2', 'C#5', 'C5', 'A2', 'F#6', 'C#4', 'F#1', 'B6', 'B-6', 'E-2', 'C#7', 'B4', 'C#3', 'F1', 'E6', 'F5', 'B-5', 'F7', 'G#1', 'E-4', 'D2', 'G#6', 'F6', 'B1', 'C#6', 'F3', 'G6', 'D5', 'G4', 'G#5', 'F#3', 'E5', 'A6', 'B-3', 'E2', 'B5', 'C4', 'A1', 'E-3', 'G5', 'D3', 'G2', 'B-4', 'F4', 'G3', 'B2', 'E1', 'G#2', 'C2', 'F2', 'G1', 'B-1', 'D4', 'A5', 'D6', 'C6', 'E3', 'C7', 'E-7', 'E-6', 'G#3', 'F#4', 'B3', 'E-5', 'G#4', 'D7', 'C3', 'A3', 'F#2', 'B-2', 'D1', 'A4', 'F#5', 'E4', 'E7']\n",
      "['3.0', '12.0', '2.25', '2.0', '3.75', '2.75', '0.25', '2/3', '4.75', '0.0', '12.25', '3.5', '1.0', '4.0', '8.0', '7/3', '4.5', '0.75', '6.0', '5/3', '1.5', '1.25', '5.0', '2.5', '0.5', '4/3', '7.25', '37/3', '1/3']\n",
      "[8, 41, 103, 15, 17, 31, 1, 7, 27, 43, 5, 29, 5, 1, 13, 55, 69, 4, 1, 92, 37, 14, 26, 5, 14, 72, 39, 145, 126, 54, 33, 29, 18, 111, 15, 16, 91, 2, 85, 101, 78, 43, 125, 59, 94, 15, 2, 2, 10, 15, 10, 12, 116, 52, 47, 43, 38, 12, 6, 33, 68, 55, 34, 86, 72, 12, 34, 65, 12, 81, 1, 78, 65, 37, 4]\n",
      "[108, 1, 1, 90, 2, 1, 1203, 3, 1, 30, 1, 8, 531, 7, 1, 1, 1, 16, 3, 1, 32, 4, 1, 23, 932, 5, 1, 1, 107]\n"
     ]
    }
   ],
   "source": [
    "notes = []\n",
    "durs = []\n",
    "offsets = []\n",
    "for file in glob.glob(\"midi_s2/*.mid\"):\n",
    "    notes_file = []\n",
    "    durs_file = []\n",
    "    offsets_file = []\n",
    "    midi = converter.parse(file)\n",
    "    print(\"Parsing %s\" % file)\n",
    "    notes_to_parse = None\n",
    "    #try: # file has instrument parts\n",
    "    #    s2 = instrument.partitionByInstrument(midi)\n",
    "    #    notes_to_parse = s2.parts[0].recurse() \n",
    "    #except: # file has notes in a flat structure\n",
    "    notes_to_parse = midi.flat.notes\n",
    "    print(len(notes_to_parse))\n",
    "    for element in notes_to_parse:\n",
    "        if isinstance(element, note.Note):\n",
    "            notes_file.append(str(element.pitch))\n",
    "        elif isinstance(element, chord.Chord):\n",
    "            notes_file.append(str(element.root()))\n",
    "        durs_file.append(str(element.quarterLength))\n",
    "        offsets_file.append(str(element.quarterLength))\n",
    "    notes.append(notes_file)\n",
    "    durs.append(durs_file)\n",
    "    offsets.append(offsets_file)\n",
    "\n",
    "#np.array_equal(offsets[0],durs[0])\n",
    "ind_notes = list(set([item for sublist in notes for item in sublist]))\n",
    "ind_durs = list(set([item for sublist in durs for item in sublist]))\n",
    "print(ind_notes)\n",
    "print(ind_durs)\n",
    "print([[item for sublist in notes for item in sublist].count(item) for item in ind_notes])\n",
    "print([[item for sublist in durs for item in sublist].count(item) for item in ind_durs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = 200\n",
    "\n",
    "pits_dataq = np.empty((0, seq))\n",
    "durs_dataq = np.empty((0, seq))\n",
    "\n",
    "for song in range(len(notes)):\n",
    "    song_notes_i = np.array([ind_notes.index(x) for x in notes[song]])\n",
    "    song_durs_i = np.array([ind_durs.index(x) for x in durs[song]])\n",
    "    nseq = int(np.floor(song_notes_i.shape[0] / seq)) # throw away end of song\n",
    "    pits_dataq = np.concatenate((pits_dataq, np.reshape(song_notes_i[:nseq*seq], (-1, seq))))\n",
    "    durs_dataq = np.concatenate((durs_dataq, np.reshape(song_durs_i[:nseq*seq], (-1, seq))))\n",
    "pitch_nq = len(ind_notes)\n",
    "dur_nq = len(ind_durs)\n",
    "pitch_scale = pitch_nq - 1\n",
    "dur_scale = dur_nq - 1\n",
    "pits_data = 2 * (pits_dataq / pitch_scale - 0.5)\n",
    "durs_data = 2 * (durs_dataq / dur_scale - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "Number of train seqs: 15\n",
      "Model total params: 1300904\n",
      "Step: 642 --- NLL: 0.1278852522  Epoch   642: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Step: 4999 --- NLL: 0.0079557840  "
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "hidden_size = 300\n",
    "fr_len = 4\n",
    "\n",
    "class Sequence(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Sequence, self).__init__()\n",
    "        self.pWz2 = nn.Linear(hidden_size+fr_len, hidden_size) #pitch tier2 GRU\n",
    "        self.pWr2 = nn.Linear(hidden_size+fr_len, hidden_size) #pitch tier2 GRU\n",
    "        self.pWh2 = nn.Linear(hidden_size+fr_len, hidden_size) #pitch tier2 GRU\n",
    "        self.pWz = nn.Linear(2*hidden_size+1, hidden_size) #pitch GRU\n",
    "        self.pWr = nn.Linear(2*hidden_size+1, hidden_size) #pitch GRU\n",
    "        self.pWh = nn.Linear(2*hidden_size+1, hidden_size) #pitch GRU\n",
    "        self.pO2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.pO = nn.Linear(hidden_size, pitch_nq)\n",
    "        self.dWz = nn.Linear(hidden_size+2, hidden_size) #pitch GRU\n",
    "        self.dWr = nn.Linear(hidden_size+2, hidden_size) #pitch GRU\n",
    "        self.dWh = nn.Linear(hidden_size+2, hidden_size) #pitch GRU\n",
    "        self.dO2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dO = nn.Linear(hidden_size, dur_nq)\n",
    "        \n",
    "    def pitch_tier2_model(self, x, h2):\n",
    "        z2 = torch.sigmoid(self.pWz2(torch.cat([h2, x], dim=1)))\n",
    "        r2 = torch.sigmoid(self.pWr2(torch.cat([h2, x], dim=1)))       \n",
    "        hh2 = torch.tanh(self.pWh2(torch.cat([r2 * h2, x], dim=1)))\n",
    "        h2 = (1 - z2) * h2 + z2 * hh2\n",
    "        return h2\n",
    "        \n",
    "    def pitch_model(self, x, h, h2): # P(pitch cur|pitch hist,pitch tier2 hist)\n",
    "        z = torch.sigmoid(self.pWz(torch.cat([h, h2, x], dim=1))) \n",
    "        r = torch.sigmoid(self.pWr(torch.cat([h, h2, x], dim=1)))       \n",
    "        hh = torch.tanh(self.pWh(torch.cat([r * h, h2, x], dim=1)))\n",
    "        h = (1 - z) * h + z * hh\n",
    "        o = self.pO(torch.relu(self.pO2(h)))\n",
    "        return o, h\n",
    "    \n",
    "    def dur_model(self, x, x2, h): # P(dur cur|dur hist,pitch cur)\n",
    "        z = torch.sigmoid(self.dWz(torch.cat([h, x, x2], dim=1)))\n",
    "        r = torch.sigmoid(self.dWr(torch.cat([h, x, x2], dim=1)))       \n",
    "        hh = torch.tanh(self.dWh(torch.cat([r * h, x, x2], dim=1)))\n",
    "        h = (1 - z) * h + z * hh\n",
    "        o = self.dO(torch.relu(self.dO2(h)))\n",
    "        return o, h\n",
    "\n",
    "    def forward(self, pitch_input, dur_input, pitch_ref, generate=False, future = 0):\n",
    "        pitch_outputs = []\n",
    "        pitch_genputs = np.empty((pitch_input.shape))\n",
    "        dur_outputs = []\n",
    "        dur_genputs = np.empty((dur_input.shape))\n",
    "        ph_t = torch.zeros(pitch_input.size(0), hidden_size, dtype=torch.float32, device=device)\n",
    "        ph2_t = torch.zeros(pitch_input.size(0), hidden_size, dtype=torch.float32, device=device)\n",
    "        pitch_input2_t = torch.zeros(pitch_input.size(0), fr_len, dtype=torch.float32, device=device)  \n",
    "        dh_t = torch.zeros(dur_input.size(0), hidden_size, dtype=torch.float32, device=device)\n",
    "        for i, (pitch_input_t, dur_input_t, pitch_ref_t) in enumerate(zip(pitch_input.chunk(pitch_input.size(1), dim=1), dur_input.chunk(dur_input.size(1), dim=1), pitch_ref.chunk(pitch_ref.size(1), dim=1))):\n",
    "            pitch_output, ph_t = self.pitch_model(pitch_input_t, ph_t, ph2_t)\n",
    "            pitch_outputs += [pitch_output]              \n",
    "            if (i+1) % fr_len == 0:\n",
    "                pitch_input2_t = pitch_input[:,i-fr_len+1:i+1]\n",
    "                ph2_t = self.pitch_tier2_model(pitch_input2_t, ph2_t)\n",
    "            dur_output, dh_t = self.dur_model(dur_input_t, pitch_ref_t, dh_t)\n",
    "            dur_outputs += [dur_output]\n",
    "            if generate:                           \n",
    "                probabilities = nn.functional.softmax(pitch_output, dim=-1).cpu().data.numpy()\n",
    "                pitch_genput = np.empty(pitch_output.shape[0])\n",
    "                for bi in range(pitch_output.shape[0]):\n",
    "                    pitch_genput[bi] = 2 * (int(np.random.choice(np.arange(pitch_nq), p=probabilities[bi])) / pitch_scale - 0.5)\n",
    "                pitch_genputs[:,i] = pitch_genput\n",
    "                probabilities = nn.functional.softmax(dur_output, dim=-1).cpu().data.numpy()\n",
    "                dur_genput = np.empty(dur_output.shape[0])\n",
    "                for bi in range(dur_output.shape[0]):\n",
    "                    dur_genput[bi] = 2 * (int(np.random.choice(np.arange(dur_nq), p=probabilities[bi])) / dur_scale - 0.5)\n",
    "                dur_genputs[:,i] = dur_genput                                                      \n",
    "        if generate:\n",
    "            for fi in range(future):\n",
    "                pitch_genput_torch = torch.from_numpy(pitch_genput[:,None]).float().to(device)\n",
    "                if fi % fr_len == 0:\n",
    "                    pitch_genput2_torch = torch.from_numpy(pitch_genputs[:,-fr_len:]).float().to(device)\n",
    "                    ph2_t = self.pitch_tier2_model(pitch_genput2_torch, ph2_t)                   \n",
    "                pitch_output, ph_t = self.pitch_model(pitch_genput_torch, ph_t, ph2_t)\n",
    "                pitch_outputs += [pitch_output]                                                       \n",
    "                probabilities = nn.functional.softmax(pitch_output, dim=-1).cpu().data.numpy()\n",
    "                pitch_genput = np.empty(pitch_output.shape[0])\n",
    "                for bi in range(pitch_output.shape[0]):\n",
    "                    pitch_genput[bi] = 2 * (int(np.random.choice(np.arange(pitch_nq), p=probabilities[bi])) / pitch_scale - 0.5)\n",
    "                pitch_genputs = np.concatenate((pitch_genputs,pitch_genput[:,None]), axis=1)\n",
    "                pitch_genput_torch = torch.from_numpy(pitch_genput[:,None]).float().to(device) # handle more efficient?\n",
    "                dur_genput_torch = torch.from_numpy(dur_genput[:,None]).float().to(device)                                                    \n",
    "                dur_output, dh_t = self.dur_model(dur_genput_torch, pitch_genput_torch, dh_t)\n",
    "                dur_outputs += [dur_output]  \n",
    "                probabilities = nn.functional.softmax(dur_output, dim=-1).cpu().data.numpy()\n",
    "                dur_genput = np.empty(dur_output.shape[0])\n",
    "                for bi in range(dur_output.shape[0]):\n",
    "                    dur_genput[bi] = 2 * (int(np.random.choice(np.arange(dur_nq), p=probabilities[bi])) / dur_scale - 0.5)\n",
    "                dur_genputs = np.concatenate((dur_genputs,dur_genput[:,None]), axis=1)                                                   \n",
    "        pitch_outputs = torch.stack(pitch_outputs, 1).squeeze(2)\n",
    "        dur_outputs = torch.stack(dur_outputs, 1).squeeze(2)\n",
    "        return pitch_outputs, pitch_genputs, dur_outputs, dur_genputs\n",
    "    \n",
    "pits_inp = torch.from_numpy(pits_data[:, :-1]).float().to(device)\n",
    "pits_ref = torch.from_numpy(pits_data[:, 1:]).float().to(device)\n",
    "pits_target = torch.from_numpy(pits_dataq[:, 1:]).long().to(device)\n",
    "durs_inp = torch.from_numpy(durs_data[:, :-1]).float().to(device)\n",
    "durs_target = torch.from_numpy(durs_dataq[:, 1:]).long().to(device)                                                                   \n",
    "seq = Sequence().to(device)\n",
    "print('Number of train seqs: ' + str(pits_inp.shape[0]))\n",
    "print('Model total params: ' + str(sum(p.numel() for p in seq.parameters() if p.requires_grad)))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(seq.parameters(), lr=0.001)#\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=20, verbose=True)\n",
    "for i in range(6000):\n",
    "    optimizer.zero_grad()\n",
    "    pits_out, _, durs_out, _ = seq(pits_inp, durs_inp, pits_ref)\n",
    "    loss_pitch = criterion(pits_out.permute(2,0,1).view(pitch_nq,-1).permute(1,0), pits_target.view(-1))#view(-1,batch_size*time_steps)\n",
    "    loss_dur = criterion(durs_out.permute(2,0,1).view(dur_nq,-1).permute(1,0), durs_target.view(-1))\n",
    "    loss = loss_pitch + loss_dur\n",
    "    sys.stdout.write('\\rStep: %i --- NLL: %.10f  ' % (i, loss))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'test_output.mid'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init = 10\n",
    "pits_test_inp = torch.from_numpy(pits_data[init:init+1, :-1]).float().to(device)\n",
    "pits_test_ref = torch.from_numpy(pits_data[init:init+1, 1:]).float().to(device)\n",
    "pits_test_target = torch.from_numpy(pits_dataq[init:init+1, 1:]).long().to(device)\n",
    "durs_test_inp = torch.from_numpy(durs_data[init:init+1, :-1]).float().to(device)\n",
    "durs_test_target = torch.from_numpy(durs_dataq[init:init+1, 1:]).long().to(device)   \n",
    "with torch.no_grad():\n",
    "    _, pitch_pred, _, dur_pred = seq(pits_test_inp, durs_test_inp, pits_test_ref, generate=True, future=500)\n",
    "print('done')\n",
    "pits_syn = np.round((pitch_pred / 2.0 + 0.5) * pitch_scale)\n",
    "durs_syn = np.round((dur_pred / 2.0 + 0.5) * dur_scale)\n",
    "output_notes = []\n",
    "offset = 0\n",
    "for n in range(pits_syn[0].shape[0]):\n",
    "    d = eval(ind_durs[int(durs_syn[0][n])])\n",
    "    new_note = note.Note(pitch=ind_notes[int(pits_syn[0][n])], quarterLength=d)\n",
    "    new_note.offset = offset\n",
    "    offset += d\n",
    "    new_note.storedInstrument = instrument.Piano()\n",
    "    output_notes.append(new_note)\n",
    "\n",
    "midi_stream = stream.Stream(output_notes)\n",
    "midi_stream.write('midi', fp='test_output.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
